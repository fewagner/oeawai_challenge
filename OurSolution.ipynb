{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:19.141124Z",
     "start_time": "2019-08-09T06:19:19.130380Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "from IPython.display import Audio\n",
    "import torch.optim as optim\n",
    "from types import SimpleNamespace\n",
    "import scipy.signal as sc\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from trainDataset import TrainDataset\n",
    "from testDataset import TestDataset\n",
    "#from trainDatasetNew import TrainDatasetNew\n",
    "#from testDatasetNew import TestDatasetNew\n",
    "from validation_split import get_dataloaders\n",
    "from math_utils import logMagStft, ffts\n",
    "from SpectrogramCNN import SpectrogramCNN\n",
    "from train_utils import train, test\n",
    "from evaluation_utils import get_mean_F1\n",
    "from MulitScale1DResNet import MSResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:19.150636Z",
     "start_time": "2019-08-09T06:19:19.142949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with cuda\n"
     ]
    }
   ],
   "source": [
    "validation_split = .2\n",
    "do_plots = False\n",
    "load_model = True\n",
    "args = SimpleNamespace(batch_size=32, test_batch_size=32, epochs=5,\n",
    "                       lr=0.01, momentum=0.5, seed=1, log_interval=200, \n",
    "                      net = MSResNet)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not torch.cuda.is_available(): # adapt those paths on other machine\n",
    "    print('no cuda')\n",
    "    path_train = './../data/train-small/'\n",
    "    path_test =  './../data/test/kaggle-test/'\n",
    "else:\n",
    "    print('with cuda')\n",
    "    path_train = './../data/kaggle-train/'\n",
    "    path_test =  './../data/kaggle-test/'\n",
    "    \n",
    "path_model = 'models/model.pt'\n",
    "path_submission = 'submissions/'\n",
    "    \n",
    "sample_rate = 16000\n",
    "nmbr_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.457018Z",
     "start_time": "2019-08-09T06:19:19.152398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269776\n",
      "4096\n"
     ]
    }
   ],
   "source": [
    "# todo add in the classes the features and the fft data\n",
    "\n",
    "toFloat = transforms.Lambda(lambda x: x / np.iinfo(np.int16).max)\n",
    "\n",
    "trainDataset = TrainDataset(path_train, transform=toFloat)\n",
    "print(len(trainDataset))\n",
    "\n",
    "testDataset = TestDataset(path_test, transform=toFloat)\n",
    "print(len(testDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.461514Z",
     "start_time": "2019-08-09T06:19:20.458548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  64000\n"
     ]
    }
   ],
   "source": [
    "input_size = len(trainDataset[0][0])\n",
    "print('input size: ',input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Look at Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.466660Z",
     "start_time": "2019-08-09T06:19:20.462714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if do_plots:\n",
    "    # how many instruments are there?\n",
    "    dummy_count = np.zeros(20)\n",
    "\n",
    "    for sample in trainDataset:\n",
    "        dummy_count[sample[1]] += 1\n",
    "\n",
    "    labels_count = []\n",
    "    for elem in dummy_count:\n",
    "        if elem != 0:\n",
    "            labels_count.append(elem)\n",
    "\n",
    "    print(labels_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.470673Z",
     "start_time": "2019-08-09T06:19:20.468085Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if do_plots:\n",
    "    nmbr_classes = len(labels_count)\n",
    "    print('nmbr_classes: ', nmbr_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.474324Z",
     "start_time": "2019-08-09T06:19:20.471823Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if do_plots:\n",
    "    plt.plot(labels_count, '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.478959Z",
     "start_time": "2019-08-09T06:19:20.476144Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if do_plots:\n",
    "    # plot one of each\n",
    "\n",
    "    done = np.zeros(nmbr_classes)\n",
    "    examples = []\n",
    "\n",
    "    for sample in trainDataset:\n",
    "        if done[sample[1]] == 0:\n",
    "            examples.append(sample)\n",
    "            done[sample[1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.491179Z",
     "start_time": "2019-08-09T06:19:20.480373Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if do_plots:\n",
    "    plt.subplot(431)\n",
    "    plt.plot(examples[0][0])\n",
    "\n",
    "    plt.subplot(432)\n",
    "    plt.plot(examples[1][0])\n",
    "\n",
    "    plt.subplot(433)\n",
    "    plt.plot(examples[2][0])\n",
    "\n",
    "    plt.subplot(434)\n",
    "    plt.plot(examples[3][0])\n",
    "\n",
    "    plt.subplot(435)\n",
    "    plt.plot(examples[4][0])\n",
    "\n",
    "    plt.subplot(436)\n",
    "    plt.plot(examples[5][0])\n",
    "\n",
    "    plt.subplot(437)\n",
    "    plt.plot(examples[6][0])\n",
    "\n",
    "    plt.subplot(438)\n",
    "    plt.plot(examples[7][0])\n",
    "\n",
    "    plt.subplot(439)\n",
    "    plt.plot(examples[8][0])\n",
    "\n",
    "    plt.subplot(4,3,10)\n",
    "    plt.plot(examples[9][0])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.497957Z",
     "start_time": "2019-08-09T06:19:20.492434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if do_plots:\n",
    "\n",
    "    # plot one of each in FFT\n",
    "\n",
    "    plt.subplot(431)\n",
    "    plt.plot(ffts(examples[0][0]))\n",
    "\n",
    "    plt.subplot(432)\n",
    "    plt.plot(ffts(examples[1][0]))\n",
    "\n",
    "    plt.subplot(433)\n",
    "    plt.plot(ffts(examples[2][0]))\n",
    "\n",
    "    plt.subplot(434)\n",
    "    plt.plot(ffts(examples[3][0]))\n",
    "\n",
    "    plt.subplot(435)\n",
    "    plt.plot(ffts(examples[4][0]))\n",
    "\n",
    "    plt.subplot(436)\n",
    "    plt.plot(ffts(examples[5][0]))\n",
    "\n",
    "    plt.subplot(437)\n",
    "    plt.plot(ffts(examples[6][0]))\n",
    "\n",
    "    plt.subplot(438)\n",
    "    plt.plot(ffts(examples[7][0]))\n",
    "\n",
    "    plt.subplot(439)\n",
    "    plt.plot(ffts(examples[8][0]))\n",
    "\n",
    "    plt.subplot(4,3,10)\n",
    "    plt.plot(ffts(examples[9][0]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.501777Z",
     "start_time": "2019-08-09T06:19:20.499137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if do_plots:\n",
    "\n",
    "    for sample in examples:\n",
    "        display(Audio(sample[0], rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.619268Z",
     "start_time": "2019-08-09T06:19:20.502911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64000]) torch.Size([32]) tensor([7, 8, 0, 6, 4, 4, 6, 4, 5, 6, 6, 7, 3, 1, 4, 1, 3, 0, 0, 3, 0, 0, 6, 1,\n",
      "        6, 6, 7, 9, 2, 4, 3, 0])\n",
      "tensor(-0.9476, dtype=torch.float64) tensor(0.9468, dtype=torch.float64)\n",
      "['reed' 'string' 'bass' 'organ' 'keyboard' 'keyboard' 'organ' 'keyboard'\n",
      " 'mallet' 'organ' 'organ' 'reed' 'guitar' 'brass' 'keyboard' 'brass'\n",
      " 'guitar' 'bass' 'bass' 'guitar' 'bass' 'bass' 'organ' 'brass' 'organ'\n",
      " 'organ' 'reed' 'vocal' 'flute' 'keyboard' 'guitar' 'bass']\n",
      "torch.Size([32, 64000]) torch.Size([32]) tensor([3, 0, 6, 2, 0, 4, 0, 8, 6, 4, 1, 4, 0, 2, 7, 0, 6, 2, 4, 5, 0, 8, 8, 5,\n",
      "        1, 3, 4, 0, 5, 5, 3, 0])\n",
      "tensor(-0.9475, dtype=torch.float64) tensor(0.9853, dtype=torch.float64)\n",
      "['guitar' 'bass' 'organ' 'flute' 'bass' 'keyboard' 'bass' 'string' 'organ'\n",
      " 'keyboard' 'brass' 'keyboard' 'bass' 'flute' 'reed' 'bass' 'organ'\n",
      " 'flute' 'keyboard' 'mallet' 'bass' 'string' 'string' 'mallet' 'brass'\n",
      " 'guitar' 'keyboard' 'bass' 'mallet' 'mallet' 'guitar' 'bass']\n"
     ]
    }
   ],
   "source": [
    "# validation split is done here\n",
    "\n",
    "train_loader, validation_loader = get_dataloaders(trainDataset, \n",
    "                                                  batch_size = args.batch_size, \n",
    "                                                  validation_split = validation_split, \n",
    "                                                  shuffle_dataset = True, \n",
    "                                                  random_seed = None)\n",
    "\n",
    "for samples, instrument_family_target in train_loader:\n",
    "        print(samples.shape, instrument_family_target.shape,\n",
    "              instrument_family_target.data)\n",
    "        print(torch.min(samples), torch.max(samples))\n",
    "        print(trainDataset.transformInstrumentsFamilyToString(instrument_family_target.data))\n",
    "        break\n",
    "        \n",
    "for samples, instrument_family_target in validation_loader:\n",
    "        print(samples.shape, instrument_family_target.shape,\n",
    "              instrument_family_target.data)\n",
    "        print(torch.min(samples), torch.max(samples))\n",
    "        print(trainDataset.transformInstrumentsFamilyToString(instrument_family_target.data))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.642405Z",
     "start_time": "2019-08-09T06:19:20.620454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64000])\n",
      "tensor(-0.9471, dtype=torch.float64) tensor(0.9469, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "test_loader = data.DataLoader(testDataset, batch_size=args.batch_size, shuffle=False) #!!! shuffle should be false\n",
    "for samples in test_loader:\n",
    "        print(samples[0].shape)\n",
    "        print(torch.min(samples[0]), torch.max(samples[0]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:20.645767Z",
     "start_time": "2019-08-09T06:19:20.643713Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.net == SpectrogramCNN:\n",
    "    model = args.net(device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:23.000020Z",
     "start_time": "2019-08-09T06:19:20.647793Z"
    }
   },
   "outputs": [],
   "source": [
    "if args.net == MSResNet:\n",
    "    model = args.net(1, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:23.004275Z",
     "start_time": "2019-08-09T06:19:23.001289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSResNet(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer3x3_1): Sequential(\n",
      "    (0): BasicBlock3x3(\n",
      "      (conv1): Conv1d(64, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 32, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3x3_2): Sequential(\n",
      "    (0): BasicBlock3x3(\n",
      "      (conv1): Conv1d(32, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(32, 64, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3x3_3): Sequential(\n",
      "    (0): BasicBlock3x3(\n",
      "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3x3_4): Sequential(\n",
      "    (0): BasicBlock3x3(\n",
      "      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool3): AvgPool1d(kernel_size=(16,), stride=(1,), padding=(0,))\n",
      "  (layer5x5_1): Sequential(\n",
      "    (0): BasicBlock5x5(\n",
      "      (conv1): Conv1d(64, 32, kernel_size=(5,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 32, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer5x5_2): Sequential(\n",
      "    (0): BasicBlock5x5(\n",
      "      (conv1): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(32, 64, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer5x5_3): Sequential(\n",
      "    (0): BasicBlock5x5(\n",
      "      (conv1): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer5x5_4): Sequential(\n",
      "    (0): BasicBlock5x5(\n",
      "      (conv1): Conv1d(128, 256, kernel_size=(5,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool5): AvgPool1d(kernel_size=(11,), stride=(1,), padding=(0,))\n",
      "  (layer7x7_1): Sequential(\n",
      "    (0): BasicBlock7x7(\n",
      "      (conv1): Conv1d(64, 32, kernel_size=(7,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 32, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer7x7_2): Sequential(\n",
      "    (0): BasicBlock7x7(\n",
      "      (conv1): Conv1d(32, 64, kernel_size=(7,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(32, 64, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer7x7_3): Sequential(\n",
      "    (0): BasicBlock7x7(\n",
      "      (conv1): Conv1d(64, 128, kernel_size=(7,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer7x7_4): Sequential(\n",
      "    (0): BasicBlock7x7(\n",
      "      (conv1): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(1,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool7): AvgPool1d(kernel_size=(6,), stride=(1,), padding=(0,))\n",
      "  (fc): Linear(in_features=85760, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:19:23.008441Z",
     "start_time": "2019-08-09T06:19:23.005399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "info = {'lowest F1' : 100,\n",
    "        'saved epoch' : None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-09T06:19:31.802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/269776 (0%)]\tLoss: 2.310546\tF1: 0.1250\tRuntime: 0.5\n",
      "Train Epoch: 1 [6400/269776 (3%)]\tLoss: 2.325633\tF1: 0.1875\tRuntime: 33.0\n",
      "Train Epoch: 1 [12800/269776 (6%)]\tLoss: 1.576162\tF1: 0.3750\tRuntime: 65.5\n",
      "Train Epoch: 1 [19200/269776 (9%)]\tLoss: 1.510457\tF1: 0.5312\tRuntime: 98.1\n",
      "Train Epoch: 1 [25600/269776 (12%)]\tLoss: 1.996844\tF1: 0.4375\tRuntime: 130.6\n",
      "Train Epoch: 1 [32000/269776 (15%)]\tLoss: 1.430485\tF1: 0.5312\tRuntime: 163.1\n",
      "Train Epoch: 1 [38400/269776 (18%)]\tLoss: 1.727321\tF1: 0.3750\tRuntime: 195.7\n",
      "Train Epoch: 1 [44800/269776 (21%)]\tLoss: 1.616256\tF1: 0.4375\tRuntime: 228.2\n",
      "Train Epoch: 1 [51200/269776 (24%)]\tLoss: 0.778842\tF1: 0.7812\tRuntime: 260.8\n",
      "Train Epoch: 1 [57600/269776 (27%)]\tLoss: 1.116545\tF1: 0.6250\tRuntime: 293.4\n",
      "Train Epoch: 1 [64000/269776 (30%)]\tLoss: 1.108325\tF1: 0.5312\tRuntime: 325.9\n",
      "Train Epoch: 1 [70400/269776 (33%)]\tLoss: 1.137844\tF1: 0.5938\tRuntime: 358.7\n",
      "Train Epoch: 1 [76800/269776 (36%)]\tLoss: 1.545747\tF1: 0.4062\tRuntime: 391.3\n",
      "Train Epoch: 1 [83200/269776 (39%)]\tLoss: 0.905817\tF1: 0.6562\tRuntime: 423.8\n",
      "Train Epoch: 1 [89600/269776 (42%)]\tLoss: 1.073750\tF1: 0.5312\tRuntime: 456.4\n",
      "Train Epoch: 1 [96000/269776 (44%)]\tLoss: 1.075709\tF1: 0.6250\tRuntime: 489.0\n",
      "Train Epoch: 1 [102400/269776 (47%)]\tLoss: 1.277641\tF1: 0.5000\tRuntime: 521.5\n",
      "Train Epoch: 1 [108800/269776 (50%)]\tLoss: 0.970660\tF1: 0.6250\tRuntime: 554.1\n",
      "Train Epoch: 1 [115200/269776 (53%)]\tLoss: 1.168675\tF1: 0.6250\tRuntime: 586.7\n",
      "Train Epoch: 1 [121600/269776 (56%)]\tLoss: 0.893140\tF1: 0.7188\tRuntime: 619.3\n",
      "Train Epoch: 1 [128000/269776 (59%)]\tLoss: 0.657989\tF1: 0.6875\tRuntime: 651.8\n",
      "Train Epoch: 1 [134400/269776 (62%)]\tLoss: 1.257128\tF1: 0.5312\tRuntime: 684.4\n",
      "Train Epoch: 1 [140800/269776 (65%)]\tLoss: 1.035420\tF1: 0.5938\tRuntime: 717.0\n",
      "Train Epoch: 1 [147200/269776 (68%)]\tLoss: 0.940922\tF1: 0.5938\tRuntime: 749.5\n",
      "Train Epoch: 1 [153600/269776 (71%)]\tLoss: 0.895842\tF1: 0.6562\tRuntime: 782.1\n",
      "Train Epoch: 1 [160000/269776 (74%)]\tLoss: 0.836905\tF1: 0.6562\tRuntime: 814.7\n",
      "Train Epoch: 1 [166400/269776 (77%)]\tLoss: 0.677568\tF1: 0.8438\tRuntime: 847.3\n",
      "Train Epoch: 1 [172800/269776 (80%)]\tLoss: 0.853228\tF1: 0.6562\tRuntime: 879.9\n",
      "Train Epoch: 1 [179200/269776 (83%)]\tLoss: 0.678320\tF1: 0.8125\tRuntime: 912.5\n",
      "Train Epoch: 1 [185600/269776 (86%)]\tLoss: 1.142423\tF1: 0.6250\tRuntime: 945.0\n",
      "Train Epoch: 1 [192000/269776 (89%)]\tLoss: 0.969952\tF1: 0.6250\tRuntime: 977.6\n",
      "Train Epoch: 1 [198400/269776 (92%)]\tLoss: 0.770690\tF1: 0.7188\tRuntime: 1010.2\n",
      "Train Epoch: 1 [204800/269776 (95%)]\tLoss: 0.774383\tF1: 0.6875\tRuntime: 1042.7\n",
      "Train Epoch: 1 [211200/269776 (98%)]\tLoss: 0.992206\tF1: 0.5625\tRuntime: 1075.3\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch, start_time = time.time())\n",
    "    f1 = get_mean_F1(model, validation_loader)\n",
    "    print('after epoch {} got f1 score of {}'.format(epoch , f1))\n",
    "    if f1 < info['lowest F1']:\n",
    "        info['lowest F1'] = np.copy(f1)\n",
    "        info['saved epoch'] = epoch \n",
    "        test(args, model, device, test_loader, epoch, trainDataset, testDataset, path_submission)\n",
    "        torch.save(model, path_model)\n",
    "        print('currently best model --> saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T19:40:19.435196Z",
     "start_time": "2019-08-08T19:40:17.698491Z"
    }
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    model = torch.load(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:09:23.836943Z",
     "start_time": "2019-08-09T06:07:56.707546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8749073525051865"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mean_F1(model, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T06:09:32.602603Z",
     "start_time": "2019-08-09T06:09:23.881686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved predictions\n"
     ]
    }
   ],
   "source": [
    "epoch=10\n",
    "test(args, model, device, test_loader, epoch, trainDataset, testDataset, path_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
